const OpenAI = require('openai');
const logger = require('./logger');

class LLMService {
  constructor(apiKey, model = 'gpt-3.5-turbo') {
    if (!apiKey || apiKey === 'your_openai_api_key_here') {
      logger.warn('OpenAI API key not provided, using mock responses');
      this.useMock = true;
    } else {
      this.client = new OpenAI({ apiKey });
      this.model = model;
      this.useMock = false;
    }
    
    this.maxTokens = parseInt(process.env.MAX_TOKENS) || 500;
    this.temperature = parseFloat(process.env.LLM_TEMPERATURE) || 0.7;
  }

  async generateResponse(prompt, context = []) {
    if (this.useMock) {
      return this.generateMockResponse(prompt, context);
    }

    try {
      const systemMessage = this.buildSystemMessage();
      const userMessage = this.buildUserMessage(prompt, context);

      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          { role: 'system', content: systemMessage },
          { role: 'user', content: userMessage }
        ],
        max_tokens: this.maxTokens,
        temperature: this.temperature,
      });

      return {
        answer: response.choices[0].message.content.trim(),
        usage: response.usage,
        model: this.model
      };
    } catch (error) {
      logger.error('Error generating LLM response:', error.message);
      throw new Error(`Failed to generate response: ${error.message}`);
    }
  }

  buildSystemMessage() {
    return `You are a helpful AI assistant that answers questions based on the provided context. 
Follow these guidelines:
1. Use only the information provided in the context to answer questions
2. If the context doesn't contain enough information, say so clearly
3. Be concise and accurate
4. Cite relevant parts of the context when possible
5. Don't make up information not present in the context`;
  }

  buildUserMessage(query, context) {
    const contextText = context
      .map((doc, index) => `[${index + 1}] ${doc.text}`)
      .join('\n\n');

    return `Context:
${contextText}

Question: ${query}

Please provide a comprehensive answer based on the context above.`;
  }

  generateMockResponse(prompt, context) {
    const contextSummary = context.length > 0 
      ? `Based on ${context.length} relevant document(s), ` 
      : 'Without specific context, ';
    
    return {
      answer: `${contextSummary}here's a mock response to your query: "${prompt}". This is a simulated response since no OpenAI API key was provided. In a real scenario, this would be generated by GPT-3.5-turbo using the provided context.`,
      usage: { prompt_tokens: 100, completion_tokens: 50, total_tokens: 150 },
      model: 'mock-model'
    };
  }
}

module.exports = LLMService;
